---
layout: default
---


### About Me

<img class="profile-picture" src="profile.jpg">

Hi! I am a third year PhD student at University of Maryland, College Park. I graduated with my B.Tech in Computer Science from IIT Delhi in 2014. 

### Research Interests

**Provable defenses against adversarial examples:** The phenomenon of adversarial examples has established that neural networks are brittle and not robust to small targeted perturbations. Empirical defenses are often broken by newer and stronger attacks leading to unreliable robustness guarantees. Instead, my work derives provable defenses which provide a differentiable and guaranteed robustness certificate on the output of the neural network and can be used to train convolutional neural networks with robustness guarantees.

**Failure explanation of deep neural networks:** Most of the previous work on discovering failure modes of deep neural networks requires a human to first hypothesize *what could be the possible failure mode?* and then collection of metadata via crowdsourcing to validate the hypothesis. However, this approach often requires an expensive and time-consuming labeling of metadata by humans. My approach circumvents the aforementioned issue and allows the discovery of failure modes without manual annotating for visual attributes.


### Publications

* Understanding Impacts of High-Order Loss Approximations and Features in Deep Learning Interpretation. **ICML 2019** \\
**Sahil Singla**, Eric Wallace, Shi Feng, Soheil Feizi.
* Second-Order provable defenses against Adversarial Examples. **ICML 2020**\\
**Sahil Singla**, Soheil Feizi. 
* Fantastic Four: Differentiable and Efficient Bounds on Singular Values of Convolution Layers. **ICLR 2021**\\
**Sahil Singla**, Soheil Feizi. 
* Perceptual Adversarial Robustness: Defense Against Unseen Threat Models. **ICLR 2021**\\
Cassidy Laidlaw, **Sahil Singla**, Soheil Feizi. 
* Skew Orthogonal Convolutions. **ICML 2021**\\
**Sahil Singla**, Soheil Feizi. 
* Fairness Through Robustness: Investigating Robustness Disparity in Deep Learning. **FAccT (formerly FAT), 2021**\\
Vedant Nanda, Samuel Dooley, **Sahil Singla**, Soheil Feizi, John Dickerson.
* Understanding Failures of Deep Networks via Robust Feature Extraction. **CVPR, 2021 (Oral)**\\
Vasu Singla, **Sahil Singla**, David Jacobs, Soheil Feizi.
* Low Curvature Activations Reduce Overfitting in Adversarial Training. **ICCV, 2021**\\
**Sahil Singla**, Besmira Nushi, Shital Shah, Ece Kamar, Eric Horvitz.
* Certifiably Robust Interpretation in Deep Learning. Under review. Short version accepted at NeurIPS Workshop on Machine Learning with Guarantees, 2019. \\
Alexander Levine, **Sahil Singla**, Soheil Feizi. 
* Robustness Certificates Against Adversarial Examples for ReLU Networks. Under review.\\
 **Sahil Singla**, Soheil Feizi.
